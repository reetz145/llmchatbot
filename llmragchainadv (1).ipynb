{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4880325,"sourceType":"datasetVersion","datasetId":2829865},{"sourceId":7402493,"sourceType":"datasetVersion","datasetId":4304581},{"sourceId":7404251,"sourceType":"datasetVersion","datasetId":4305717},{"sourceId":7404272,"sourceType":"datasetVersion","datasetId":4305734},{"sourceId":7405739,"sourceType":"datasetVersion","datasetId":4306789},{"sourceId":7407866,"sourceType":"datasetVersion","datasetId":4308391},{"sourceId":7425729,"sourceType":"datasetVersion","datasetId":4320708},{"sourceId":7427525,"sourceType":"datasetVersion","datasetId":4322012},{"sourceId":7430193,"sourceType":"datasetVersion","datasetId":4323830}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install fpdf","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-18T19:07:41.591705Z","iopub.execute_input":"2024-01-18T19:07:41.592083Z","iopub.status.idle":"2024-01-18T19:08:00.397541Z","shell.execute_reply.started":"2024-01-18T19:07:41.592051Z","shell.execute_reply":"2024-01-18T19:08:00.396039Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting fpdf\n  Downloading fpdf-1.7.2.tar.gz (39 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: fpdf\n  Building wheel for fpdf (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40704 sha256=9dc08ff091d950d9ef9b20eff58b3755d0168c5089a8d3771669647b1a5af146\n  Stored in directory: /root/.cache/pip/wheels/f9/95/ba/f418094659025eb9611f17cbcaf2334236bf39a0c3453ea455\nSuccessfully built fpdf\nInstalling collected packages: fpdf\nSuccessfully installed fpdf-1.7.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\n! pip install  -U -qq langchain tiktoken pypdf faiss-gpu\n! pip install  -U -qq InstructorEmbedding sentence_transformers","metadata":{"execution":{"iopub.status.busy":"2024-01-18T19:08:02.844665Z","iopub.execute_input":"2024-01-18T19:08:02.845076Z","iopub.status.idle":"2024-01-18T19:08:52.823377Z","shell.execute_reply.started":"2024-01-18T19:08:02.845043Z","shell.execute_reply":"2024-01-18T19:08:52.822218Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\ndask-cuda 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\ndask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\njupyterlab 4.0.10 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.24.3 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.4 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\nraft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mCPU times: user 855 ms, sys: 184 ms, total: 1.04 s\nWall time: 50 s\n","output_type":"stream"}]},{"cell_type":"code","source":"import re\nimport os\nimport torch\nimport random\nimport numpy as np\nimport pandas as pd\nfrom operator import itemgetter\nimport langchain\nfrom langchain.schema import format_document\nfrom langchain.schema.messages import get_buffer_string\nfrom langchain.document_loaders import PyPDFLoader, DirectoryLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain import PromptTemplate, LLMChain\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain.vectorstores import FAISS\nfrom langchain.llms import HuggingFacePipeline\nfrom InstructorEmbedding import INSTRUCTOR\nfrom langchain.embeddings import HuggingFaceInstructEmbeddings\nfrom langchain.chains import RetrievalQA\nfrom langchain.schema.output_parser import StrOutputParser\nfrom langchain.schema.runnable import RunnableLambda, RunnablePassthrough,RunnableParallel\nfrom langchain.schema.messages import HumanMessage, SystemMessage, AIMessage\nimport torch\nimport transformers\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline","metadata":{"execution":{"iopub.status.busy":"2024-01-18T10:46:30.882351Z","iopub.execute_input":"2024-01-18T10:46:30.882699Z","iopub.status.idle":"2024-01-18T10:46:50.798794Z","shell.execute_reply.started":"2024-01-18T10:46:30.882674Z","shell.execute_reply":"2024-01-18T10:46:50.798016Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/InstructorEmbedding/instructor.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n  from tqdm.autonotebook import trange\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONASSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(seed=42)\n\nimport locale\nlocale.getpreferredencoding = lambda: \"UTF-8\"","metadata":{"execution":{"iopub.status.busy":"2024-01-18T10:46:56.868710Z","iopub.execute_input":"2024-01-18T10:46:56.869467Z","iopub.status.idle":"2024-01-18T10:46:56.886544Z","shell.execute_reply.started":"2024-01-18T10:46:56.869430Z","shell.execute_reply":"2024-01-18T10:46:56.885480Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class ChatBot:\n    \n    def __init__(self,\n                 model,\n                 tokenizer,\n                 embeddings,\n                 pdf_path = None,\n                 chat_history = [],\n                 max_len = 1000,\n                 temperature = 0,\n                 top_p = 0.95,\n                 repetition_penalty = 1.15,\n                 split_chunk_size = 800,\n                 split_overlap = 0,\n                 k = 3,\n                 device = \"cuda\",\n                 do_sample = True,\n                 ## vector db\n                 vector_db_save_path = \"faiss_index_hp\",\n                 vector_db_load_path = None,\n                 ## templates\n                 answer_template = None,\n                 condensed_question_template = None,\n                 pipe = None,\n                ):\n        self.model = model\n        self.tokenizer = tokenizer\n        self.embeddings = embeddings\n        if tokenizer.pad_token is None:\n            tokenizer.pad_token = tokenizer.eos_token\n        self.pdf_path = pdf_path\n        self.chat_history = chat_history\n        self.max_len = max_len\n        self.temperature = temperature\n        self.top_p = top_p\n        self.repetition_penalty = repetition_penalty\n        self.split_chunk_size = split_chunk_size\n        self.split_overlap = split_overlap\n        self.k = k\n        self.device = device\n        self.do_sample = do_sample\n        self.vector_db_save_path = vector_db_save_path\n        self.vector_db_load_path = vector_db_load_path\n        \n        \n        # templates\n        if answer_template is None:\n            self.answer_template  = \"\"\"Answer the question based only on the following context:\n                                        {context}\n\n                                        Question: {question}\n                                    \"\"\"\n        self.answer_prompt = ChatPromptTemplate.from_template(self.answer_template)\n        \n        if condensed_question_template is None:\n            self.condensed_question_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n\n                                                Chat History:\n                                                {chat_history}\n                                                Follow Up Input: {question}\n                                                Standalone question:\n                                                \"\"\"\n        \n        self.condensed_question_prompt = PromptTemplate.from_template(self.condensed_question_template)\n        \n        ## llm pipeline \n        if pipe is None:\n            pipe = pipeline(\n                task = \"text-generation\",\n                model = self.model,\n                tokenizer = self.tokenizer,\n                pad_token_id = self.tokenizer.eos_token_id,\n                max_length = self.max_len,\n                repetition_penalty = self.repetition_penalty\n            )\n\n        self.llm = HuggingFacePipeline(pipeline = pipe)\n        \n    def load_pdf(self):\n        loader = DirectoryLoader(\n            self.pdf_path,\n            glob=\"./*.pdf\",\n            loader_cls=PyPDFLoader,\n            show_progress=True,\n            use_multithreading=True\n        )\n\n        self.documents = loader.load()\n\n        text_splitter = RecursiveCharacterTextSplitter(\n            chunk_size = self.split_chunk_size,\n            chunk_overlap = self.split_overlap\n        )\n\n        self.texts = text_splitter.split_documents(self.documents)        \n        \n    \n    def create_vector_db(self):\n        self.vectordb = FAISS.from_documents(\n            documents = self.texts, \n            embedding = self.embeddings\n        )\n\n        self.vectordb.save_local(self.vector_db_save_path)\n            \n    def load_vector_db(self):\n        self.vectordb = FAISS.load_local(\n            self.vector_db_load_path,\n            self.embeddings\n        )\n        \n    def create_chat_qa_chain(self):\n        \n        if self.vector_db_load_path:\n            self.load_vector_db()\n        else:\n            if self.pdf_path is not None:\n                self.load_pdf()\n                self.create_vector_db()\n                self.vector_db_load_path = self.vector_db_save_path\n                self.load_vector_db()\n        \n        retriever = None\n        if hasattr(self,\"vectordb\"):\n            retriever = self.vectordb.as_retriever(search_kwargs = {\"k\": self.k, \"search_type\" : \"similarity\"})\n        \n        _inputs = RunnableParallel(\n                    standalone_question=RunnablePassthrough.assign(\n                        chat_history=lambda x: get_buffer_string(x[\"chat_history\"])\n                    )\n                    | self.condensed_question_prompt\n                    | self.llm\n                    | StrOutputParser(),\n                )\n        if retriever is None:\n            _context = {\n                \"context\": itemgetter(\"standalone_question\"),\n                \"question\": lambda x: x[\"standalone_question\"],\n            }\n        else:\n            _context = {\n                \"context\": itemgetter(\"standalone_question\") | retriever,\n                \"question\": lambda x: x[\"standalone_question\"],\n            }\n        \n        self.chain = (\n                _inputs\n                | _context\n                | self.answer_prompt\n                | self.llm\n                |StrOutputParser()\n        )\n    \n    def clean_response(self,response):\n        return response.replace(\"Answer:\",\"\").strip()\n    \n    def start_chat(self):\n        self.create_chat_qa_chain()\n        \n        while True:\n            user_input = input(\"You:\")\n            if user_input.lower().strip() == \"bye\":\n                break\n            model_input = {\n                \"question\": user_input,\n                \"chat_history\": self.chat_history,\n            }\n            response = self.chain.invoke(model_input)\n            print(\"AI:\",self.clean_response(response))\n            #giving context of only last two responses\n            self.chat_history = self.chat_history[-2:]\n            self.chat_history.extend(\n                [\n                    HumanMessage(content=user_input),\n                    AIMessage(content=self.clean_response(response))\n                ]\n            )\n            print()\n            \n    def save(self, save_directory):\n        self.model.save_pretrained(save_directory)\n        self.tokenizer.save_pretrained(save_directory)\n\n        attributes_to_save = {\n            \"pdf_path\": self.pdf_path,\n            \"chat_history\": self.chat_history,\n        }\n\n        with open(os.path.join(save_directory, \"attributes.json\"), \"w\") as f:\n            json.dump(attributes_to_save, f)\n\n    def load(self, load_directory):\n        self.model = AutoModelForCausalLM.from_pretrained(load_directory)\n        self.tokenizer = AutoTokenizer.from_pretrained(load_directory)\n\n        with open(os.path.join(load_directory, \"attributes.json\"), \"r\") as f:\n            loaded_attributes = json.load(f)\n\n        self.pdf_path = loaded_attributes.get(\"pdf_path\", None)\n        self.chat_history = loaded_attributes.get(\"chat_history\", [])\n    \n    def process_user_input(self, user_input):\n        model_input = {\n            \"question\": user_input,\n            \"chat_history\": self.chat_history,\n        }\n        response = self.chain.invoke(model_input)\n        return self.clean_response(response)\n    \n            ","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:00:49.810297Z","iopub.execute_input":"2024-01-18T11:00:49.810807Z","iopub.status.idle":"2024-01-18T11:00:49.849618Z","shell.execute_reply.started":"2024-01-18T11:00:49.810767Z","shell.execute_reply":"2024-01-18T11:00:49.848486Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"config = {\n    \"seed\":42,\n    \"model_path\":\"mistralai/Mistral-7B-Instruct-v0.1\",\n    \"embeddings_model_path\":\"sentence-transformers/all-MiniLM-L6-v2\",\n    \"pdf_path\":\"/kaggle/input/pdfsubmission\",\n    \"vector_db_save_path\":\"faiss_index_hp\",\n    \"vector_db_load_path\":\"faiss_index_hp\",\n    \"device\":\"cuda\"\n}","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:00:58.208380Z","iopub.execute_input":"2024-01-18T11:00:58.208751Z","iopub.status.idle":"2024-01-18T11:00:58.213624Z","shell.execute_reply.started":"2024-01-18T11:00:58.208722Z","shell.execute_reply":"2024-01-18T11:00:58.212700Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(config[\"model_path\"],\n                                            device_map='auto',\n                                            torch_dtype=torch.float16,\n                                            low_cpu_mem_usage=True)\ntokenizer = AutoTokenizer.from_pretrained(config[\"model_path\"])\nembeddings = HuggingFaceInstructEmbeddings(model_name = config[\"embeddings_model_path\"],\n                                           model_kwargs = {\"device\":config[\"device\"]})","metadata":{"execution":{"iopub.status.busy":"2024-01-18T10:47:10.673952Z","iopub.execute_input":"2024-01-18T10:47:10.674710Z","iopub.status.idle":"2024-01-18T10:52:04.458040Z","shell.execute_reply.started":"2024-01-18T10:47:10.674675Z","shell.execute_reply":"2024-01-18T10:52:04.457103Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5beb09f30ae34c9093ad583a5d5715ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42b90df095ce4f5d810a94f4c66b25c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7238a9ff49f94f9cb1be06069ed8ea89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3731a500ee54b1f8cd4e49dfa21a110"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36b060007df84c1e9f02d6f0187329a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6cd5293e4b94a0ab080e9e36884c5c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92db946908aa430fb172d05ade65f14e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3e4d0c3f49f45b98109660201381bac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9870b27da834a0b8667aceaa056917c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7be6249afff4378b3d96beb08dd586d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68db4f5c92294713abdf712500cfaf0e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":".gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f429924ca4a45328bceda2c9e627173"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd7bf790edeb42a29d707201b855e824"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a97258e43de846a081033769c26bc132"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abd93f0cf26a4092802a0232b416fd13"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce6a3d01ae8f4df3a43fcd47f5c0ff0e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"378c8ab26c4b4d8ea70d9e82b199c23b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdb05a5b3db6443fb7b32df4b45d211f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4313c9f9f3fb4ad8a45465e9ca6d77bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6253c92a385f487fbb4fc154598e936d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a4ed39e471d475186b7258a3ccd4899"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8de19902eef94b4ea498e3735f18e3c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c076156556bd417295a1a6627212e9b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d951ffa565c74e61a65c3ff44ac133a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c60f8fa793b94079908ddaa3065719d0"}},"metadata":{}},{"name":"stdout","text":"load INSTRUCTOR_Transformer\nmax_seq_length  512\n","output_type":"stream"}]},{"cell_type":"code","source":"chat_bot = ChatBot(model,\n                   tokenizer,\n                   embeddings,\n                   pdf_path=config[\"pdf_path\"],\n                  )","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:01:05.266574Z","iopub.execute_input":"2024-01-18T11:01:05.266957Z","iopub.status.idle":"2024-01-18T11:01:05.272403Z","shell.execute_reply.started":"2024-01-18T11:01:05.266928Z","shell.execute_reply":"2024-01-18T11:01:05.271449Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"import json\nchat_bot.save(\"/kaggle/working/save\")","metadata":{"execution":{"iopub.status.busy":"2024-01-18T10:52:44.056890Z","iopub.execute_input":"2024-01-18T10:52:44.057549Z","iopub.status.idle":"2024-01-18T10:53:36.846228Z","shell.execute_reply.started":"2024-01-18T10:52:44.057512Z","shell.execute_reply":"2024-01-18T10:53:36.845141Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"chat_bot.start_chat()","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:47:09.161059Z","iopub.execute_input":"2024-01-18T11:47:09.162119Z","iopub.status.idle":"2024-01-18T11:59:16.178085Z","shell.execute_reply.started":"2024-01-18T11:47:09.162083Z","shell.execute_reply":"2024-01-18T11:59:16.177242Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"100%|██████████| 4/4 [01:01<00:00, 15.40s/it]\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You: financial disclosure document of bigb coffee\n"},{"name":"stdout","text":"AI: The financial disclosure document for BigB Coffee is included in the Franchise Disclosure Document (FDD). Specifically, items 21 and 20 in the FDD include financial statements that can help determine the stability, growth, and competition in the franchise system. Additionally, item 12 describes the territory provisions in the franchise agreement that outline whether the franchisor and other franchisees can compete with each other.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You: Wahlburgers Franchising LLC\n"},{"name":"stdout","text":"AI: The financial disclosure requirements for Wahlburgers Franchising LLC include providing Item 19 which gives information about outlet sales, costs, profits or losses. Additionally, it is recommended to obtain this information from others, such as current and former franchisees whose names and contact information can be found in Item 20 or Exhibit E.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You: For Bloomin Blinds\n"},{"name":"stdout","text":"AI: The financial disclosure requirements for Blooming Blinds include providing financial statements (Exhibit E) and a list of all assets owned by the company (Exhibit A).\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You: in detail\n"},{"name":"stdout","text":"AI: The specific financial disclosure requirements for Blooming Blinds can be found in Exhibit A, which lists all assets of the debtor, both real and personal, tangible and intangible, existing or hereafter acquired. Additionally, financial statements can be found in Exhibit E.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You: whats tangible and intangible assets??\n"},{"name":"stdout","text":"AI: Tangible assets include physical items such as vehicles, computer and office equipment, furniture and fixtures, and leasehold improvements. Intangible assets include non-physical items such as intellectual property, supporting obligations, contract rights, insurance claims, tort claims, and general intangibles.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You: okay any speciality about financial disclosure of amazing athelets, any special difference\n"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"AI: No, there are no specific financial disclosure requirements for professional athletes.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You: i am asking for Amazing Athletes Franchise Systems, LLC\n"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"AI: The financial disclosure requirement for Amazing Athletes Franchise Systems, LLC is that they must provide audited financial statements to the prospective franchisee 14 calendar days before signing a binding agreement with or making a payment to the franchisor or an affiliate in connection with the proposed franchise sale. Additionally, they must provide these financial statements as Exhibit E attached to the disclosure document.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You: now describe in detail about atomic wings\n"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"AI: Atomic Wings is a restaurant chain that has franchises in various locations. The document provided contains an agreement between Atomic Wings Franchisor Inc. and an area representative for one of their franchises.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You: in detail\n"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"AI: Based on the provided documents, Atomic Wings Franchisor Inc.'s agreement with an area representative for one of their franchises contains information about the franchisor's legal history, financial stability, growth potential, competition from other franchisees, and any restrictions on the territory they can operate in.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You: what about the THE MICHIGAN FRANCHISE INVESTMENT LAW\n"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"AI: According to the information provided in the PDF document, Michigan requires that Atomic Wings Franchisor Inc. provide a disclosure document to the area representative at least 10 business days before the execution of any binding franchise or other agreement or the payment of any consideration, whichever occurs first. If the disclosure document is not delivered on time or contains false or misleading statements or material omissions, a violation of federal and state law may have occurred and should be reported to the Federal Trade Commission and the state authority listed on Exhibit E. Additionally, the franchise agreement must be retained by the area representative, along with any other materials related to operating the franchised business, but no copies or records of these materials can be kept beyond what is necessary for compliance with any provision of law.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You: in a difference of all of the companies can you list out the differences in detail of their financial disclosure\n"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"AI: Atomic Wings Franchisor Inc. provides financial disclosures related to their actual or potential financial performance of their franchised and/or franchisor-owned outlets. They also provide an audit report which provides a reasonable basis for their opinion on the accuracy of their financial statements. The Burger Joint and The Pizza Place do not provide such detailed financial disclosures.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You: okay thank you so much'\n"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"AI: Atomic Wings Franchisor Inc. provides financial disclosures related to their actual or potential financial performance of their franchised and/or franchisor-owned outlets. They also provide an audit report that presents fairly, in all material respects, the financial position of Atomic Wings Franchisor Inc. as of December 31, 2018, and their ability to provide support to their business.\n                                        \n                                        On the other hand, The Burger Joint and The Pizza Place do not provide any financial disclosures related to their actual or potential financial performance of their franchised and/or franchisor-owned outlets. However, they both provide information about the stability, growth, and competition in their respective franchise systems.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You: bye\n"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chat_bot.start_chat()","metadata":{"execution":{"iopub.status.busy":"2024-01-15T15:31:33.038673Z","iopub.execute_input":"2024-01-15T15:31:33.038978Z","iopub.status.idle":"2024-01-15T15:35:18.009741Z","shell.execute_reply.started":"2024-01-15T15:31:33.038954Z","shell.execute_reply":"2024-01-15T15:35:18.008643Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"100%|██████████| 3/3 [00:05<00:00,  1.88s/it]\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You: rcession on world and indian economy\n"},{"name":"stdout","text":"AI: Based on the provided documents, it seems that there is concern about a potential recession affecting not only the United States but also the global economy. Additionally, India's economy is facing challenges such as rising unemployment despite recent growth. However, it is important to note that the analysis presented in the documents may not necessarily reflect the current state of the world and Indian economy.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You: fastest growing economic nation\n"},{"name":"stdout","text":"AI: Some of the fastest-growing economies in the world include India, China, Germany, USA, Japan, and others. According to a report by the World Bank, India's share in world output is projected to jump from 5% as of today to 20.8% by 2040.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You: what about inflation\n"},{"name":"stdout","text":"AI: The text does not provide information about the current inflation rate in India.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You: of the world\n"},{"name":"stdout","text":"AI: Some of the fastest-growing economies in the world include India, China, Germany, USA, Japan, and others. According to a report by the World Bank, India's share in world output is projected to jump from 5% as of today to 20.8% by 2040.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You: inflation around the world\n"},{"name":"stdout","text":"AI: The inflation rate for goods purchased online in the US slowed sharply last month while food prices increased at the fastest pace on record, according to the Adobe Digital Price Index. Meanwhile, European Commission forecasts inflation at 7.6% in 2022 and 2023 with a peak in Q3 2022 and a drop below 3% in Q4 2023. The German economy had strong H1 despite the Ukraine war and Russian gas deliveries uncertainty clouding the H2 outlook. Turkish industrial production was estimated at 0.3% mm and 80% yy in May. Swiss producer and import prices were estimated at 69% mm and 69% yy in June. The UK inflation came in hot, surging to a 40-year high of 94%.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You: some developments in big mncs\n"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"AI: Big multinational corporations are collaborating with other companies, making changes to their internal structures and processes, expanding into new markets, and investing heavily in technology and innovation. Some examples include Akzo Nobel's decision to prioritize home improvements, Barclays' aim to increase its presence in Germany, and Samsung's planned $200 billion investment in Austin. Additionally, there has been a shift towards sustainable practices and green initiatives among many companies, such as the Japanese company Loral Japan's collaboration with its Green Science Project.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You: okay thank you\n"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"AI: Big multinational corporations are collaborating with other companies, making changes to their internal structures and processes, expanding into new markets, and investing heavily in technology and innovation. Some examples include Akzo Nobel's decision to prioritize home improvements, Barclays' aim to increase its presence in Germany, and Samsung's planned $200 billion investment in Austin. Additionally, there has been a shift towards sustainable practices and green initiatives among many companies, such as the Japanese company Loral Japan's collaboration with its Green Science Project.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You: bye\n"}]}]}